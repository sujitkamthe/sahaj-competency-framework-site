# Framework Design Decisions & Context

This document captures design decisions and organizational context for the Sahaj competency framework. Not part of the public website.

## Why This Framework Exists

Sahaj is an open org with open feedback. Without a shared structure:
- People give feedback on only 1-2 dimensions where they're strong or weak
- There's no common language to debate growth and impact
- Expectations are set by teammates and vary inconsistently
- People can't see why others with similar work get paid significantly more
- Self-assessment overclaiming is common and hard to calibrate

**Critical: This is NOT a promotion ladder.**

Sahaj has no titles. Everyone is a "Solution Consultant." There are no roles to anchor on. Growth is amorphous and self-driven. This framework doesn't change that — it provides **clarity and shared vocabulary** for understanding where you are and where you could go.

Personas are not titles or levels. They describe the **nature of your contribution**.

## How Assessment Works

### The Process
1. Individuals collect feedback from everyone they work with (teams, cross-team, other initiatives)
2. They update their self-assessment on a **public sheet** and announce who provided feedback
3. Feedback providers who disagree (or missed giving feedback) have conversations with the individual
4. The **entire office reviews all self-assessments as a group** to surface disagreements
5. Disagreements are discussed **privately**; resulting changes are **public**

### Participants
- The individual
- Their immediate team
- Everyone in the office (group calibration)

### Office Structure
- Offices are ~30-50 people each
- Multiple offices exist
- Office leads sync up to ensure consistency across offices

### Current State (Pre-Framework)
- Self-assessment uses "below / met / exceeded expectations"
- Expectations are set by teammates (inconsistent across teams)
- No shared vocabulary or persona language yet
- Freeform feedback (hoping framework adds structure)

### Compensation
Personas are tied to compensation bands. Higher impact = higher compensation.

Salaries are currently hard to calibrate without a shared framework. People often feel "I'm doing the same thing as others getting paid more" because they can't see what different expectation levels actually look like.

## Key Failure Modes to Prevent

1. **Inconsistent assessment across the group** — different standards applied to different people
2. **Inflated self-assessment** — people claiming higher than reality, which blocks actual growth (they won't learn if they think they're already there)

## Design Principles

### Pull-Based Growth
Sahaj is a pull-based org. The organization attempts to create growth opportunities, but individuals must:
- Be clear about their growth goals
- Actively pull information and opportunities they need

### No IC-Only Track
Even ICs must scale their impact. The question is *how* they scale, not *whether* they need to.

(Note: Discussion pending on acknowledging non-people-leadership scaling paths like platforms, tooling, standards-setting, external influence.)

### Specialists vs Generalists
Evaluated on balance of skills + individual performance. Not a strict generalist requirement, but polyglot capability is expected.

## Open Questions

### Removing Years of Experience
Current state: Each persona has a years range (e.g., "4-8 Years" for Catalyst).

Decision: Remove years entirely as an anchor.

Replacement anchors under consideration:
- **Scope of impact**: Task → Feature → Project → Team → Org
- **Nature of contribution**: Executing → Shaping how → Defining what → Enabling others → Setting direction
- **Question you're trusted to answer**: "How do I do this?" → "What should we build?" → "Where should Sahaj go?"

Concerns:
- Scope depends on opportunity (not fully in your control)
- "Question you're trusted to answer" is context-dependent — you might perform at Catalyst level on a familiar team but not replicate it elsewhere

### Handling Uneven Growth Across Capabilities
Problem: Someone is Catalyst-level in Technical Delivery but Artisan-level in Consulting. What are they?

Options considered:
- Option A: Lowest capability determines level (strict, may feel punitive)
- Option B: Primary/secondary capabilities with different weights at different levels
- Option C: No single label; describe the shape of growth across capabilities
- Option D: Persona as aspiration, not assessment

Leaning toward: Option B (primary/secondary), but needs more thought.

Concern: Self-assessment inflation if not structured carefully.

### Context-Dependent Performance
Problem: Someone performs at Catalyst level on their current team (familiar domain, built trust over time), but may operate at Artisan level on a new team.

**How Sahaj handles this today:**
- It happens. Self-assessments drop based on feedback in the new context.
- The org supports people through growth.
- They get slightly lower hikes that year.
- They get compensated better when they improve.

This is considered normal, not a failure. The system self-corrects through feedback.

### Opportunity-Seeking
- Should be explicitly part of expectations
- Sahaj creates opportunity mechanisms as part of growth support
- But growth is pull-based — individuals must seek and drive their own opportunities
- If someone wants to work on a capability but hasn't had opportunity, they're explicit about it and the org works to make it available

## Framework Scope

### Priority Order (for building it together)
1. **First:** People who grow to lead teams (the majority)
2. **Next:** ICs who scale impact without people-leadership
3. **Later:** Non-delivery roles

The goal is to cover the majority first, then expand. Both paths (team leadership and IC) should feel equally valid.

### Trident Model Influence
Inspired by [Pat Kua's Trident Model](https://www.patkua.com/blog/the-trident-model-of-career-development/):
- **Management Track**: 70-80% time on leading people, supporting staff
- **Technical Leadership Track**: 70-80% time guiding others on technical matters (Tech Lead, Principal, Architect)
- **Individual Contributor Track**: Focused on execution and deep specialization

Key insight: Technical leadership is distinct from both management and pure execution. The framework should recognize this.

### Not Everyone Fits
The framework won't apply to everyone. If it applies to most developers on teams, that's a good start. It will evolve.

## Anti-Checkboxism: Preventing Gaming

### The Risk
The worst outcome is the framework becoming:
1. A checkbox exercise ("I did X, Y, Z, therefore I'm a Catalyst")
2. A salary negotiation toolkit ("The framework says X, so I deserve Y")
3. A promotion competition rather than genuine growth

### What Sahaj Already Has Working
- **Group calibration**: Entire office reviews self-assessments — catches inflation
- **Public self-assessment with announced sources**: Transparency creates accountability
- **Private disagreement, public changes**: Maintains trust while allowing correction
- **Pull-based culture**: Growth is self-driven, not handed out
- **Open salaries**: Everyone can see everyone's compensation
- **Open salary hikes**: Hike decisions are transparent
- **Unlimited leaves**: Trust-based, not tracked
- **Active weeding out of bad behavior**: People look out for gaming and call it out

This is a high-trust, high-transparency environment. The framework must support this, not become a tool for gaming it.

### Patterns From Research

**1. Evidence over claims**
Don't let people claim "I do Catalyst-level Consulting." Require: "Here's what changed because of my Consulting work." The framework should prompt for concrete examples, not self-ratings.

**2. Outcome language over activity language**
Bad: "I attended client meetings and gave input"
Good: "The client changed their roadmap because of how I reframed the problem"

The self-assessment questions already lean this way ("What changed because of me?"). Double down on this.

**3. "Would I give this problem to this person?"**
One calibration heuristic: Instead of "did they check this box?", ask "If I had a Catalyst-level problem, would I trust this person with it?"

**4. Ongoing feedback, not episodic assessment**
[Medium's engineering growth framework](https://medium.com/s/engineering-growth-framework/engineering-growth-assessing-progress-743620e70763) moved away from high-stakes twice-yearly reviews to ongoing conversations. This reduces the "performance theater" of review season.

**5. Acknowledge opportunity explicitly**
Distinguish:
- "I haven't had the chance to demonstrate this" (opportunity gap)
- "I had the chance but didn't take it" (growth area)
- "I had the chance and struggled" (development need)

These are different and should be treated differently.

**6. Peer validation, not just self-assessment**
The review panel should consider evidence and can recommend different levels than self-assessed. Multiple perspectives catch blind spots.

### The Compensation Tension
Frameworks tied to compensation create inherent pressure to claim higher. You can't eliminate this, but you can:
- Make evidence central (harder to game)
- Make calibration rigorous (peers and group catch inflation)
- Frame compensation as outcome of demonstrated impact, not reward for claiming impact

### What the Framework Language Should Avoid
- Exhaustive checklists that feel like "do all of these to level up"
- Activity-based descriptions ("attends meetings", "writes code")
- Language that implies completion ("achieved Catalyst") vs. ongoing ("demonstrating Catalyst-level impact")

### What the Framework Language Should Emphasize
- Questions for reflection, not boxes to check
- Evidence prompts ("What changed?", "Who benefited?", "What would be different if you hadn't been there?")
- The ongoing nature of growth (you don't "arrive" at a persona and stop)

---

## Website Structure Needs

**Separate "what" from "why":**
- The main content should be easy to read — what each persona looks like, what expectations are
- The "why" (philosophy, rationale, how to use it) should exist but not clutter the core reading experience

**Options to explore:**
- Collapsible "Why this matters" sections
- Separate philosophy/guide page
- Footnotes or hover explanations
- FAQ section

---

## How People Will Use This

### User Journey
1. **Onboarding**: First encounter — understanding what growth looks like at Sahaj
2. **Self-reflection**: Return when thinking about where they are
3. **Setting expectations**: Use with teammates to align on what's expected
4. **Feedback cycles**: Reference when giving/receiving feedback

### Implication for Website
- Needs to be scannable for returning users
- But also deep enough for key moments (feedback, reflection)
- Progressive disclosure: quick overview, details available when needed

## Rollout Plan

- Show to a few people first
- Grow slowly based on feedback
- Not a big-bang launch

---

## People Who Don't Fit

For those outside the framework's current scope:
- **Explicit acknowledgment**: "This is designed for delivery roles. Other roles have different growth paths."
- **Expansion plan**: "We're working on covering other paths."
- **Guidance**: "For now, talk to your office lead."

---

## Naming Decision

### Current: "The Sahaj Field Guide to Growth & Impact"

"Field Guide" was chosen over "Framework" or "Competency Model" because:
- **Framework** sounds prescriptive, corporate, HR-speak
- **Field Guide** implies practical, exploratory, something you reference when navigating unfamiliar territory

### What People Should Feel When Using It
- "I can reflect on where I am better"
- "I can understand my expectations better"
- "I can understand my feedback better"
- "I can talk about how I grow from here and what I need to work on"

### What People Should NOT Feel
- "Here are boxes I need to fit into"
- "I need to climb this ladder"
- "If I check these items, I get a raise"

### Naming Alternatives Considered
- "Growth Field Guide" ✓ (candidate)
- "Contribution Compass"
- "Impact Vocabulary"
- "Personas and Capabilities"

---

## Open Concerns (Unresolved)

1. **Uneven growth across capabilities**: How to handle someone who is Catalyst-level in one area, Artisan in another? No single approach decided yet.

2. **Non-people-leadership scaling**: How do ICs scale impact without leading teams? Need to articulate valid paths (platforms, tooling, standards, external influence).

3. **Checkboxism risk**: Even with good language, people may treat the framework as a checklist. Need to continuously reinforce the reflective intent.

4. **Years-of-experience removal**: Removing years is decided. Replacement anchors (scope, contribution type, trusted questions) need to be integrated into content.

5. **Calibration bias**: Group calibration may favor visible/high-profile work. Need mechanisms to surface important-but-invisible contributions.

---

*Last updated: 2026-01-29*
